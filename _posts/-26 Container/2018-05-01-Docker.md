---
layout: post
title: Docker介绍
categories: [-26 Container]
tags: [Docker]
number: [-20.1]
fullview: false
shortinfo: Docker介绍
---
目录
{:.article_content_title}


* TOC
{:toc}

---
{:.hr-short-left}

## 1. Docker 基础 ##

从过去以物理机和虚拟机为主体的开发运维环境，向以容器为核心的基础设施的转变过程，并不是一次温和的改革，而是涵盖了对网络，存储，调度，操作系统，分布式原理等各个方面的容器化理解和改造。

这就导致了很多初学者，对于容器技术栈表现出来的这些难题，要么知识储备不足，要么杂乱无章，无法形成体系。

对于Linux内核，分布式系统，网络，存储等方方面面的积累，并不会在Docker或者Kubernetes的文档中交代清楚。可偏偏就是它们，才是真正掌握容器技术体系的精髓所在，是每一位技术从业者需要细心修炼的"内功"。

### 1.1 白话容器技术基础

#### 1.1.0 Docker和Kubernetes的前世今生

> Paas: 应用托管，即在虚拟机上部署1个Cloud Foundry项目，然后在本地输入`cf push "我的应用"`, 就能把本地应用部署到云上。Cloud Foundry，就是这样一种Paas(其他相近的还包括Heroku, Pivotal)。Paas的核心组件就是一套应用的打包和分发机制。Cloud Foundry 为每种主流编程语言都定义了一种打包格式，而`cf push`的作用，基本上等同于用户把应用的可执行文件和启动脚本打进一个压缩包内，上传到云上Cloud Foundry的存储中。接着，Cloud Foundry会通过调度器选择一个可以运行这个应用的虚拟机，然后通知这个酒气上的Agent把应用压缩包下载下来启动。由于需要在一个虚拟机上启动很多个来自不同用户的应用，Cloud Foundry会调用操作系统的Cgroups和Namespace机制为每一个应用单独创建一个称作"沙盒"的隔离环境，然后在"沙盒"中启动这些应用进程。这样，就实现了把多个用户的应用互不干涉地在虚拟机里批量自动运行起来的目的。

Docker项目，其实就是一个这样的沙盒，和Cloud Foundry并没有不同，除了**镜像**。

CloudFoundry的打包配置，需要不断是错。它导致虽然 `cf push`确实能一键部署，但是为了实现这个一键部署，用户为每个应用打包的工作可谓一波三折，费尽心机。**而Docker镜像解决的，恰恰就是打包这个根本性的问题。**假设你的应用在本地运行，环境是CentOS 7.2 操作系统的所有文件和目录，那么只要用CentOS 7.2的ISO做一个2压缩包，再把你的应用可执行文件也压缩进去，那么无论在哪里解压这个压缩包，都可以得到与你本地测试时一样的环境。当然，你的应用也在里面！这就是Docker镜像最厉害的地方: 只要有这个压缩包在手，你就可以使用某种技术创建一个沙盒，在沙盒中解压这个压缩包，然后就可以运行你的程序了。

有了Docker镜像这个利器，Paas里最核心的打包系统一下子就没了用武之地，最让用户抓狂的大包裹成页随之消失了。

所以你只需要提供一个下载好的操作系统文件与目录，然后使用它制作一个压缩包即可，这个命令就是`$docker build 我的镜像`; 一旦镜像制作完成，用户就可以让Docker创建一个沙盒来解压这个镜像，然后在沙盒中运行自己的应用，这个命令就是`$docker run 我的镜像`。

所以，Docker项目给PaaS世界带来的"降维打击"，其实是提供了一种非常便利的打包机制。这种机制直接打爆了应用运行所需要的整个操作系统，从而保证了本地环境和云端环境的高度一致，避免了用户通过“试错”来匹配两种不同运行环境之间差异的痛苦过程。

但是Docker还缺一项Paas的功能，即大规模部署应用的职责。2014年Docker雄心勃勃的推出了原生容器集群管理项目Swarm, 不仅将这波"Caas(Container as a service)"推向了一个前所未有的高潮，更是寄托了整个Docker公司重新定义PaaS的宏伟愿望。 

无开源不生态，无生态不商业。

Swarm项目完全使用Docker项目原本的容器管理API来完成**集群管理**。

单机Docker项目: `docker run 我的项目`；
多机Docker项目: `docker run -H 我的Swarm集群API地址 我的容器`。

所以在部署了Swarm的多机环境下，用户只需要使用原先的Docker指令创建一个容器，这个请求就会被Swarm拦截下来处理，然后通过具体的调度算法找到一个合适的Docker Daemon运行起来。而此时大红大紫到不差钱的Docker公司，开始及时得借助这波浪潮通过并购来完善自己的平台层能力。其中一个最成功的案例，莫过于对Fig项目的收购。要知道，Fig项目基本上只是靠两个人全职开发和维护的，可它却是当时Github上热度堪比Docker项目的明星。

Fig项目之所以受欢迎，在于它在开发者面前第一次提出了**容器编排(Container Orchestration)**的概念，即假如现在用户需要部署的是应用容器A,数据库容器B,负载均衡容器C,那么Fig就允许用户把A,B,C三个容器定义在一个配置文件中，并且可以指定它们之间的关联关系，比如容器A需要访问数据库容器B(参考[CircleCI config.yml](https://circleci.com/docs/2.0/workflows/))。接下来，你只需要执行`fig up`，Fig就会把这些容器的定义和配置交给Docker API按照访问逻辑一次创建，你的一系列容器就都启动了；而容器A与B之间的关联关系，也会交给Docker的Link功能通过写入hosts文件的方式进行配置。更重要的是，你还可以在Fig的配置文件里定义各种容器的副本个数等编排参数，再加上Swarm的集群管理能力，一个活脱脱的PaaS呼之欲出。Fig项目被收购后改名为**Compose**。

Docker的**Compose**, **Swarm**和**Machine**三件套，在重新定义PaaS的方向上走出了最关键的一步。

Docker公司最后选择对抗来自整个云计算产业的压力，是将开源项目与商业产品精密绑定，打造了一个极端封闭的技术生态。而这，违背了Docker项目与开发者保持亲密关系的初衷。相比之下，Kubernetes社区，正是以一种更加温和的方式，承接了Docker项目的未尽事业，即: 以开发者为核心，构建一个相对民主和开放的容器生态。

**总结**:

1. 容器技术的兴起源于PaaS技术的普及；

2. Docker公司发布的Docker项目具有里程碑式的意义；

3. Docker项目通过“容器镜像”，解决了应用打包这个根本性难题；

4. 容器本身没有价值，有价值的是“容器编排”。

### 1.1 Container

{: .img_middle_hg}
![Virtual Machine vs Docker]({{site.url}}/assets/images/posts/-26_Container/2018-05-01-Docker/virtual-machine-vs-docker.png)

B比A更准确。用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的Namespace参数。而Docker项目在这里扮演的角色，更多的是旁路式的辅助和管理工作。在后续分享CRI和容器运行时的时候还会介绍到，像Docker这样的角色甚至可以去。

1. 宿主机和容器之间的兼容性。既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。尽管可以在容器里通过Mount Namesapce 单独挂载其他不同版本的操作系统文件，但这并不能改变共享宿主机内核的事实。这意味着Windoes宿主机不能运行Linux容器；低版本的Linux宿主机不能运行高版本的Linux容器。

2. 在Linux内核中，有很多资源和对象是不能被Namespace化的，最典型的例子就是时间。如果你的容器中的程序使用`settimeofday(2)`系统调用修改了时间，整个宿主机的时间都会被随之修改。


**容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”:**


1. **Cgroups(Linux Control Group)**，制造约束。限制一个进程组能够使用资源的上限，包括CPU，内存，磁盘，网络带宽等。

2. **Namespace**，修改进程视图。将进程划分为一个独立空间，使其觉得自己是各自PID Namespace里的第1号进程，只能看到各自Mount Namespace里挂载的目录和文件，只能访问到各自Network Namespace里的网络设备，就仿佛运行在一个个"容器"里面，与世隔绝。容器是个**单进程**模型，用户的应用进程实际上就是容器里PID=1的进程，也是其他后续创建的所有进程的父进程。这就意味着，在一个容器中，你没办法同时运行两个不同的应用，除非你能事先找到一个公共的PID=1的程序来充当两个不同应用的父进程，这也是为什么很多人都会用systemd或者supervisord这样的软件来代替应用本身作为容器的启动进程。在后面分享**容器设计模式**时，还会推荐其他更好的解决办法。这是因为容器本身的设计，就是希望**容器和应用能够同生命周期**，这个概念对后续的容器编排非常重要。否则，一旦出现类似于**容器是正常运行的，但是里面的应用早已经挂了**的情况，编排系统处理起来就非常麻烦了。关于单进程举个例子，比如一个镜像里集成了jdk，netstate,ping等，虽然容器启动时里面是一个java进程，但是我可以进到容器里面执行各种命令，比如netstate等，那这些命令在容器的运行过程中是在运行吗？实在运行，但它们不受docker的控制，就像野孩子。所以单进程意思不是只能运行一个进程，而是只有一个进程是可控的。


### 1.2 Kubernetes集群的搭建与实践

### 1.3 容器编排与Kubernetes核心特性剖析

### 1.4 Kubernates开源社区与生态

## 2 Summary

{: .img_middle_hg}
![kubernetes Skill Map]({{site.url}}/assets/images/posts/-26_Container/2018-05-01-Docker/kubernetes-skill-map.jpg)

- [《软件测试52讲》](https://time.geekbang.org/column/103)
- [《Jest Documentation》](https://facebook.github.io/jest/docs/en/getting-started.html).




